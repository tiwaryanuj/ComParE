{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import style\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn import linear_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devel=pd.read_csv('ComParE2017_devel.csv')\n",
    "train=pd.read_csv('ComParE2017_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>6365</th>\n",
       "      <th>6366</th>\n",
       "      <th>6367</th>\n",
       "      <th>6368</th>\n",
       "      <th>6369</th>\n",
       "      <th>6370</th>\n",
       "      <th>6371</th>\n",
       "      <th>6372</th>\n",
       "      <th>6373</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.666</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.02</td>\n",
       "      <td>-18.5</td>\n",
       "      <td>0.458</td>\n",
       "      <td>91.3</td>\n",
       "      <td>49.6</td>\n",
       "      <td>78.1</td>\n",
       "      <td>49.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.86</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.776</td>\n",
       "      <td>1.620</td>\n",
       "      <td>2.340</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.723</td>\n",
       "      <td>1.570</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>0.437</td>\n",
       "      <td>155.0</td>\n",
       "      <td>79.7</td>\n",
       "      <td>132.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.03</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.932</td>\n",
       "      <td>1.160</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.59</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.477</td>\n",
       "      <td>133.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>44.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.26</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.661</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.42</td>\n",
       "      <td>-15.3</td>\n",
       "      <td>0.337</td>\n",
       "      <td>99.4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>85.7</td>\n",
       "      <td>53.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.41</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.97</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.512</td>\n",
       "      <td>99.5</td>\n",
       "      <td>44.6</td>\n",
       "      <td>85.2</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1       2       3      4      5      6      7      8      9      10 ...  \\\n",
       "0  2.32  0.0769  0.5600  0.554  0.666  1.010  0.112  0.347  0.458  0.3630 ...   \n",
       "1  2.86  0.9780  0.8390  0.776  1.620  2.340  0.846  0.723  1.570  0.5590 ...   \n",
       "2  2.03  0.7420  0.0000  0.932  1.160  1.450  0.230  0.285  0.515  0.2640 ...   \n",
       "3  2.26  0.2500  0.9750  0.467  0.661  1.100  0.194  0.439  0.634  0.2780 ...   \n",
       "4  2.41  0.5730  0.0142  0.231  0.483  0.806  0.252  0.323  0.575  0.0575 ...   \n",
       "\n",
       "    6365  6366  6367  6368   6369   6370  6371   6372  6373  y  \n",
       "0  0.879  1.98  2.02 -18.5  0.458   91.3  49.6   78.1  49.1  0  \n",
       "1  0.490  2.45  2.60 -13.5  0.437  155.0  79.7  132.0  52.4  1  \n",
       "2  0.646  2.77  2.59  13.0  0.477  133.0  66.7   90.0  44.6  1  \n",
       "3  0.605  2.33  2.42 -15.3  0.337   99.4  51.0   85.7  53.4  1  \n",
       "4  0.450  2.00  1.97  18.2  0.512   99.5  44.6   85.2  36.9  0  \n",
       "\n",
       "[5 rows x 6374 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_tr = np.array(train.drop(['y'], 1))\n",
    "X_dev = np.array(devel.drop(['y'], 1))\n",
    "X_tr = preprocessing.scale(X_tr)\n",
    "X_dev = preprocessing.scale(X_dev)\n",
    "#df.fillna(value=-99999, inplace=True)\n",
    "#df.dropna(inplace=True)\n",
    "y_tr = np.array(train['y'])\n",
    "y_dev = np.array(devel['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3550, 6373)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feedforward neural net model\n",
    "# split data into 80-20\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# X_t, X_test, y_t, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "kf = KFold(3742, n_folds=5,shuffle=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0  loss: 0.695421677123\n",
      "train accuracy:  0.616438356164\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'recall_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-065fba52abfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mpredicted_class_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"train accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_class_tr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train recall: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_class_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mkf_train_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_class_tr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recall_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Perform batch SGD using manual backprop\n",
    "kf_train_acc=[]\n",
    "kf_val_acc=[]\n",
    "D = X_tr.shape[1] #Number of features\n",
    "K = max(y_tr)+1 #Number of classes assuming class index starts from 0\n",
    "\n",
    "# Start with an initial set of parameters randomly\n",
    "h = 10 # size of hidden layer\n",
    "W = 0.01 * np.random.randn(D,h)\n",
    "b = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initial values from hyperparameter\n",
    "reg = 1e-3 # regularization strength\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "step_size = 1e-2 #Also called learning rate\n",
    "\n",
    "for train_index, val_index in kf:\n",
    "#     print(\"TRAIN:\", train_index, \"VAL:\", val_index)\n",
    "    X_train, X_val = X_tr[train_index], X_tr[val_index]\n",
    "    y_train, y_val = y_tr[train_index], y_tr[val_index]\n",
    "    num_examples = X_train.shape[0]\n",
    "    # gradient descent loop\n",
    "    for i in range(100):\n",
    "\n",
    "      # evaluate class scores, [N x K]\n",
    "      hidden_layer = np.maximum(0, np.dot(X_train, W) + b) # note, ReLU activation\n",
    "      scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "      # compute the class probabilities\n",
    "      exp_scores = np.exp(scores)\n",
    "      probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "      # compute the loss: average cross-entropy loss and regularization\n",
    "      corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "      data_loss = np.sum(corect_logprobs)/num_examples\n",
    "      reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)\n",
    "      loss = data_loss + reg_loss\n",
    "      if i % 500 == 0:\n",
    "        print (\"iteration:\",i, \" loss:\", loss)\n",
    "\n",
    "      # compute the gradient on scores\n",
    "      dscores = probs\n",
    "      dscores[range(num_examples),y_train] -= 1\n",
    "      dscores /= num_examples\n",
    "\n",
    "      # backpropate the gradient to the parameters\n",
    "      # first backprop into parameters W2 and b2\n",
    "      dW2 = np.dot(hidden_layer.T, dscores)\n",
    "      db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "      # next backprop into hidden layer\n",
    "      dhidden = np.dot(dscores, W2.T)\n",
    "      # backprop the ReLU non-linearity\n",
    "      dhidden[hidden_layer <= 0] = 0\n",
    "      # finally into W,b\n",
    "      dW = np.dot(X_train.T, dhidden)\n",
    "      db = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "      # add regularization gradient contribution\n",
    "      dW2 += reg * W2\n",
    "      dW += reg * W\n",
    "\n",
    "      # perform a parameter update\n",
    "      W += -step_size * dW\n",
    "      b += -step_size * db\n",
    "      W2 += -step_size * dW2\n",
    "      b2 += -step_size * db2\n",
    "    \n",
    "      \n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W) + b)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class_tr = np.argmax(scores, axis=1)\n",
    "    print (\"train accuracy: \",(np.mean(predicted_class_tr == y_train)))\n",
    "    print(\"train recall: \",recall_score(y_train, predicted_class_tr))\n",
    "    kf_train_acc.append(np.mean(predicted_class_tr == y_train))\n",
    "\n",
    "    hidden_layer = np.maximum(0, np.dot(X_val, W) + b)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class_vl = np.argmax(scores, axis=1)\n",
    "    print (\"val accuracy: \",(np.mean(predicted_class_vl == y_val)))\n",
    "    print(\"val recall: \",recall_score(y_val, predicted_class_vl))\n",
    "    kf_val_acc.append(np.mean(predicted_class_vl == y_val))\n",
    "    \n",
    "print(\"cross validation-train acc:\",np.mean(kf_train_acc),\"cross validation-val acc:\",np.mean(kf_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:  0.630985915493\n",
      "0.453216374269 [[ 620  748]\n",
      " [ 562 1620]] (3550,)\n"
     ]
    }
   ],
   "source": [
    "hidden_layer = np.maximum(0, np.dot(X_dev, W) + b)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class_dv = np.argmax(scores, axis=1)\n",
    "print (\"dev accuracy: \",(np.mean(predicted_class_dv == y_dev)))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "dev_recall=recall_score(y_dev, predicted_class_dv, labels=None, pos_label=0, average='binary', sample_weight=None)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dev_conf_mtx=confusion_matrix(y_dev, predicted_class_dv, labels=None)\n",
    "print(dev_recall,dev_conf_mtx,predicted_class_dv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1108,  332],\n",
       "       [ 191, 2111]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "hidden_layer = np.maximum(0, np.dot(X_tr, W) + b)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class_tn = np.argmax(scores, axis=1)\n",
    "train_conf_mtx=confusion_matrix(y_tr, predicted_class_tn, labels=None)\n",
    "train_conf_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
